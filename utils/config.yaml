# --------------- Setup options ---------------
## run in simulation?
is_sim: true # false
## directory containing 3D mesh files (.obj) of objects to be added to simulation
obj_mesh_dir: 'envs/objects/blocks'
## number of objects to add to simulation
num_obj: 2
## IP address to robot arm as TCP client (UR5)
tcp_host_ip: '100.127.7.223'
## port to robot arm as TCP client (UR5)
tcp_port: 30002
## IP address to robot arm as real-time client (UR5)
rtc_host_ip: '100.127.7.223'
### port to robot arm as real-time client (UR5)
rtc_port: 30003
### meters per pixel of heightmap
heightmap_resolution: 0.002
### random seed for simulation and neural net initialization
random_seed: 1234

# ------------- Algorithm options -------------
## 'set to 'reactive' (supervised learning) or 'reinforcement' (reinforcement learning ie Q-learning)
method: 'reinforcement'
## use immediate rewards (from change detection) for pushing?
push_rewards: false
future_reward_discount: 0.5
## use prioritized experience replay?
experience_replay: false
## use handcrafted grasping algorithm when grasping fails too many times in a row during training?
heuristic_bootstrap: false
explore_rate_decay: false
grasp_only: true # false

# -------------- Testing options --------------
is_testing: false
## maximum number of test runs per case/scenario
max_test_trials: 30
test_preset_cases: false
test_preset_file: 'test-10-obj-01.txt'

# ------ Pre-loading and logging options ------
## load pre-trained snapshot of model?
load_snapshot: false
snapshot_file: ~
## continue logging from previous session?
continue_logging: false
logging_directory: ~
## save visualizations of FCN predictions?
save_visualizations: true # false

